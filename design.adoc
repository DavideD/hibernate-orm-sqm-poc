Design Guide
============
:toc:

== General Design

Ultimately the idea here is to redefine how Hibernate generates and executes SQL .  Part of this is the 
SQM parser for handling semantic interpretation of HQL, JPQL and criteria queries.  Part is building 
an "SQL AST" from various sources:

* SQM and options
* get & load handling (single and multi id) 
* persister-driven DML handling (save, persist, merge, etc)

Building SQM is defined by the hibernate-semantic-query project.

question - does SQM incorporate entity-graphs?  seems better to have the thing that interprets SQM to apply
entity-graphs.

question - better for persister to incorporate the model descriptor?  Or for persister to simply hold 
reference to model descriptor?  The latter seems best (certainly least disruptive), however that makes querying
MappedSuperclasses more difficult.  This really comes down to a decision of whether to model MappedSuperclass
in the EntityPersister hierarchy.  As a follow-on to this... we should incorporate a representation of
MappedSuperclass into the SQM domain model.  Seems that the spec does not allow querying MappedSuperclasses; verify!


== SQL AST

The SQL AST is a syntax tree modelling a SQL query:

* It is produced from SQM by `org.hibernate.sql.convert.spi.SqmSelectToSqlAstConverter`
* It is produced from Loaders following the old "LoadPlan" paradigm, although we will probably have
 	room for improvement
* It is consumed into a `org.hibernate.sql.exec.spi.SqlSelectInterpretation` by `org.hibernate.sql.exec.spi.SqlAstSelectInterpreter`.
	The `SqlSelectInterpretation` combines (composite) the various interpretations needed to execute and consume PreparedStatements.

[note]
----
TODO - it is counter-intuitive that a `SqlSelectInterpretation` is produced by a `SqlTreeWalker` from the result
	of a `SelectStatementInterpreter`.  The names are just "off".  Maybe instead:

* `SelectStatementInterpreter` -> `SqmToSqlAstConverter`
* `SqlTreeWalker` -> `SqlAstInterpreter`
----

=== Tables and Groups and Spaces (oh my)

Modeling the from-clause is central to SQM and its translation.  In translating SQM into an SQL AST 
we build the following types:

TableBinding:: Models a singular table (`org.hibernate.persister.common.spi.Table`) reference.  This could be either
a real table (PhysicalTable) or an inline-view (DerivedTable).

TableGroup:: Represents a related group of TableBinding instances.  Specifically it models
the TableBinding instances originating from a given entity/collection persister (see the "improved" persister contracts).

TableGroupJoin:: Represents a joined TableGroup along with the target of join and any predicate.
used to represent joins between "persister references".  These would be joins explicitly defined in the query

TableSpace:: Models what ANSI SQL calls a "table reference".  Easiest way to think of this is the comma separated groups
of "from elements".  It is a grouping of a root TableGroup, and zero-or-more TableGroupJoin instances

FromClause:: grouping of one or more TableSpaces.

Let's look at some examples to make this more clear...

[source]
.select e from Entity e (basic)
----
FromClause
    TableSpace
        root=TableGroup(com.acme.Entity, "e")
            root=TableBinding(PhysicalTable("t_entity"), "e0")
            joins={}
        joins={}
----
  
[source]
.select e from Entity e (secondary table)
----
FromClause
    TableSpace
        root=TableGroup(com.acme.Entity, "e")
            root=TableBinding(PhysicalTable("t_entity"), "e0")
            joins={
                TableJoin
                    TableBinding(PhysicalTable("t_entity_secondary"), "e1")
                    INNER
                    <join predicate>
            }
        joins={}
----
  
[source]
.select e from Entity e (joined inheritance)
----
FromClause
    TableSpace
        root=TableGroup(com.acme.Entity, "e")
            root=TableBinding(PhysicalTable("t_entity"), "e0")
            joins={
                TableJoin
                    TableBinding(PhysicalTable("t_entity_secondary"), "e1")
                    INNER
                    <join predicate>
            }
        joins={}
----

[source]
.select e from Entity e, SecondEntity se
----
FromClause
    TableSpace
        root=TableGroup(com.acme.Entity, "e")
            root=TableBinding(PhysicalTable("t_entity"), "e0")
            joins={}
        joins={}
    TableSpace
        root=TableGroup(com.acme.SecondEntity, "se")
            root=TableBinding(PhysicalTable("t_second_entity"), "se0")
            joins={}
        joins={}
----

[source]
.select e from Entity e inner join SecondEntity se on ...
----
FromClause
    TableSpace
        root=TableGroup(com.acme.Entity, "e")
            root=TableBinding(PhysicalTable("t_entity"), "e0")
            joins={}
        joins={
            TableGroupJoin
                TableGroup(com.acme.SecondEntity, "se")
		            root=TableBinding(PhysicalTable("t_second_entity"), "se0")
                    INNER
                    <join predicate>
        }
----




=== Parameters

There are multiple "parts" to parameter handling...

==== ParameterSpec

A ParameterSpec is the specification of a query parameter (name/position, target, etc).  It represents the
expectation(s) after parsing a query string.

Consider:

[source]
----
Query q = session.createQuery( "select p from Person p where p.name = :name" );
----

At this point the (Named)ParameterSpec for `":name"` has been parsed.   ParameterSpec allows for scenarios where the
SQM parser was able to ascertain an "anticipatedType" for the parameters.  Here, because `Person#name` is a `StringType`
we would anticipate `":name"` to also be a `StringType`; we will see later that ParameterBinding can adjust that.

It may also be a good idea to allow for a ParameterSpec to specify a requiredType.  This would accomodate
cases where the placement of the parameter in the query requires a certain Type to used.

Proposed ParameterSpec contract:

[source]
----
interface ParameterSpec {
    String getName();
    Integer getPosition();
    Type getAnticipatedType();
    Type getRequiredType();
}
----


==== ParameterBinding

ParameterBinding is the binding for a parameter.  Defined another way, it represents the value 
specified by the user for the parameter for this execution of the query.  

It can be thought of as the combination of a ParameterSpec, the specified value as well as some 
additional specifics like Type, TemporalType handling, etc.

This part comes from the user.  Consider:

[source]
----
Query q = session.createQuery( "from Person p where p.name = :name" );
query.setParameter( "name", "Billy" );
----

Here, the `#setParameter` call creates the ParameterBinding.  This form would
"pick up" the anticipated-Type from the ParameterSpec.  We'd also allow 
specifying the Type to use.

I think we should limit the overloaded form of this.  I can see the following options (using
named parameters for illustration):

[source]
----
interface Query {
    ...

    ParameterSpec getParameterSpec(String name);
    
    // returning this to keep API as before...

    Query setParameter(String name, Object value);
    Query setParameter(String name, Object value, Type target);
    Query setParameter(String name, Date value, TemporalType temporalType);
    Query setParameter(String name, Calendar value, TemporalType temporalType);
}
----


Proposed ParameterBinding contract:

[source]
----
interface ParameterBinding {
    ParameterSpec getParameterSpec();

    Object getValue();

    Type getType();
    TemporalType getTemporalType();
}
----


==== ParameterBinder

This is more of an esoteric concept at this point, but ultimately the idea is the binding of the 
parameter value to JDBC.  It would be best to drive the binding of parameter values from "nodes 
embedded in the query AST".  This could be a case where the implementation of ParameterSpec 
additionally implements this "binding contract" as well.


== Processing ResultSets

Processing a ResultSet means extracting the JDBC values, but also building Object graphs and using/managing the PersistenceContext.

We decided to (at least initially) reuse most of the concepts from how ResultSet processing is done in the LoadPlan
 work.  That was always meant as a preview or PoC of the work we are doing now, so that makes sense.  We just know somethings
 better now too that we'd like to incorporate.  We will go back and retrofit LoadPlan and the Loaders to use this
 new SQM-intg code.

That existing LoadPlan consuming code has a few pieces...



=== Return, Fetch and "Reader"

[note]
----
Maybe create a `HqlSelectable` interface (corollary to `SqlSelectable`) to define expressions that are valid
as a `org.hibernate.sql.ast.select.Selection`.
----

The `SelectClause` portion of the SQL AST defines its root return values via an ordered List of the individual
 `org.hibernate.sql.convert.results.spi.Return` descriptors.  Each `Return` in that List represents a single index
  in the naked Query's `Object[]` result "rows".

Some of these `Return`s represent selections of a particular entity.   This also needs to model the relationship with
 any defined join-fetches relative to that particular entity reference (literally `org.hibernate.sql.exec.results.spi.ResolvedEntityReference`).
 That is the role of `org.hibernate.sql.exec.results.spi.ResolvedFetch`.

Important because we should be able to store this Return/Fetch tree along with results in the cache and be
able to reconstruct fetch graphs.

As far as relationships:
* As the `Return#getSelectExpression` `Expression` is walked in `SqlAstSelectInterpreter`, we use a
   `SqlAstSelectInterpreter.SqlSelectableProcessor` to collect any `SqlSelectionDescriptor`s it
   produces (special handling for dynamic-instantiations).  These `SqlSelectionDescriptor`s represent
   each of the select expressions in the SQL, positionally.
* `SqlSelectionDescriptor` encapsulates a `SqlSelectable` such as a ColumnBinding or a AvgFunction call.
	This `SqlSelectable` knows how to produce a `SqlSelectionReader` for reading its value from the
	JDBC ResultSet.  This part is the key to improved (imo) integration with the QueryCache.  The first
	step in processing a row in the JDBC ResultSet is to use these `SqlSelectionReader` to build a
	`Object[]` view of the JDBC row.  It is this low level of detail that is put into the cache and
	read back.  The later "ReturnAssemblers" and "initializers" work on top of this "currentJdbcRow".
	NOTE : that this is currently messed up; see note in
	`org.hibernate.sql.exec.internal.PreparedStatementExecutorNormalImpl#execute`
* `Return` knows how to "resolve" itself to a `ResolvedReturn` based on these `SqlSelectionDescriptor`s,
	whether the Return is to be considered "shallow" and the `Expression` it encapsulates.
* `ResolvedReturn` resolves to a `ReturnAssembler` which read and "assemble" the return value into the
	`Query`'s result `Object[]` at the `Return`/`ResolvedReturn`'s position.
* `ResolvedReturn` may each register different types of "initializers" that perform various
	levels of "assembly" (fetches, dynamic instantiations, entity and collection multi-phase-loading, etc).
* The actual process of executing queries and processing results is the purpose of
	`org.hibernate.sql.exec.spi.SqlTreeExecutor` using `SqlAstSelectInterpreter`, `JdbcServices`,
	`ParameterBinder`, `PreparedStatementCreator`, `PreparedStatementExecutor`, etc.
* The "standard" (HQL and Criteria selects) `PreparedStatementExecutor` performs the JDBC
	PreparedStatement and processes the results using `QueryCacheDataAccessImplementor`,
	`ResultSetProcessingState`, `RowReader`, etc


The `org.hibernate.sql.exec.results.spi` package defines a number of contracts that it is probably beneficial to discuss:

`ResolvedReturn`:: models a return from the query.  There are 4 distinct types of `ResolvedReturn`:

* `ResolvedReturnScalar` this is something like selecting a literal, or selecting a basic singular attribute
* `ResolvedReturnDynamicInstantiation` specialized handling for dynamic-instantiations
* `ResolvedReturnEntity` represents selecting an entity either by identification variable (from alias) or to-one association
* `ResolvedReturnCollection` represents selecting a collection as the root.  This is only relevant for collection loaders

`ResolvedFetch`:: models a join fetch of a particular embeddable or entity association relative to a `ResolvedFetchParent`:

* `ResolvedFetchComposite` is the fetch of an embeddable (composite)
* `ResolvedFetchEntity` the fetch of an entity association
* todo collections (just index and element fetches?)

this stuff below is currently out of date

`CollectionReference`:: defines a reference to a collection as either a `Return` (`CollectionReturn`) or `Fetch` (`CollectionAttributeFetch`).

`EntityReference`:: defines a reference to an entity as either a `Return` (`EntityReturn`) or `Fetch` (`EntityFetch`).

`CompositeReference`:: todo : add this?


=== ResultSetProcessor and friends

At a higher level reading and processing ResultSet rows is handled by `org.hibernate.sql.exec.results.process.spi.ResultSetProcessor`
which is responsible for maintain row-position within the ResultSet.  It is also responsible for triggering "end of ResultSet processing" logic.

`ResultSetProcessor` delegates to its `org.hibernate.sql.exec.results.process.spi.RowReader` for processing each row.  This
distinction may seem like overkill, but it is important in reusing code between the ResultSetProcessor impl that builds a
`ScrollableResults` (delayed row processing) and the others (immediate row processing).

The `RowReader` delegates to the individual `ReturnReader` instances as discussed earlier.

todo : describe the usage and purpose of each of the XyzProcessingState objects, as well as the overall flow of reading results.


Much of this comes down to the following comment I added to SqlSelectionDescriptor:

[source]
----
	// todo : would be nice to hook this in with an array of the raw selection values per row.
	//		the idea being to have an array of the raw SQL row values for cases where we
	// 		need them multiple times; plus would help in terms of reading cached
	//		query results (the value array would be the same).  The array would be the same
	//		length as the SQL selections.
	//
	// also usable when building the cache entries.  Possibly as a builder contract to
	//		account for no-caching.  Maybe ResultSetProcessor could act as this contract
	//		to collect the rows to be cached.
	//
	// another option is varying levels of "reader": RawValueReader, HydratedValueReader, ResolvedValueReader
	//		RawValueReader works on the individual SqlSelectionDescriptor instances which would mean
	//		we need some resolution of SqlSelectionDescriptor->Type (possibly limited to just BasicType).
	//		But the idea here is that we could use the "RawValueReader" to manage that process from
	//		the RowProcessor, building the "sql row array" which can be cached directly and can be used
	//		by the next reader
----

todo : create a diagram illustrating what I mean wrt this code comment block


== ColumnBinding resolution

Resolving a "domain reference" to `ColumnBinding` instances involves multiple actors:

* The "domain reference" expression (and the encapsulated `org.hibernate.persister.common.spi.DomainReferenceImplementor`)
* The source (lhs, table-group, etc) of the "domain reference" expression
* The context in which the "domain reference" expression occurs
* The proper TableGroup(s) are integral as well, as they are needed to convert `Column` -> `ColumnBinding`.  Likely this just gets passed in to the ColumnBinding creation more than being a active actor in the process


At the moment this is designed as follows:

* The `DomainReferenceExpression` impls receive a `ColumnBindingSource` reference which is used to convert `Column`s into `ColumnBinding`s
* `ColumnBindingSource` is generally a `TableGroup`, but in some cases it can be a "composition" of multiple `TableGroup`s.  Can also be a "virtual" source (for `CompositeType`s)
* `DomainReferenceRenderer` handles the "contextual" aspect of rendering `DomainReferenceExpression`s into `ColumnBinding`s

The general flow is

```
DomainReferenceRenderer -> DomainReferenceExpression -> ColumnBindingSource -> DomainReference
```

This is a preliminary design.  I am in no way tied to it if anyone sees something better.


== Open Design Questions

Collection of open questions regarding various aspects of the design of this work.

=== SqlSelectionDescriptor and readers

Two questions here specifically:

1. Currently SqlSelectionDescriptor only encompasses ColumnBindings (generally speaking some form of domain reference) and misses
 	other types of expressions (function calls, literals).  The main takeaway here is that we want to well-define what is a valid
 	select expression
2. The other piece is the design of the parts needed to read back the JDBC ResultSet.  This is discussed in detail in
	the "ResultSetProcessor and friends" section.


=== Better naming for the various representations of AttributeConverter

As of the latest work on wip/6.0 we currently we have the following:

org.hibernate.cfg.AttributeConverterDefinition::
[source]
----
/*
 * Representation of an {@link AttributeConverter} from externalized sources.  Generally
 * speaking these are contributed from:<ul>
 *     <li>converters discovered via {@link Converter} discovery</li>
 *     <li>application / integration contributions - {@link org.hibernate.boot.MetadataBuilder#applyAttributeConverter}</li>
 * </ul>
 * <p/>
 * Regardless of how they are known, the set of AttributeConverterDefinition instances
 * as known to {@link org.hibernate.boot.spi.MetadataBuildingOptions#getAttributeConverters()}
 * represents the complete set of "a priori converters".  After that point the only additional
 * converters recognized would come from local {@link javax.persistence.Convert} annotations.
 */
----

org.hibernate.target.converter.spi.AttributeConverterDefinition::
[source]
----
/*
 * Internal descriptor for an AttributeConverter implementation, with the intent of being
 * incorporated into a {@link org.hibernate.target.spi.BasicType}
 */
----

So essentially the same information as `org.hibernate.cfg.AttributeConverterDefinition` but with a
a slight different intent of being incorporated int o the BasicType

org.hibernate.boot.spi.AttributeConverterDescriptor::
[source]
----
/**
 * Internal descriptor for an AttributeConverter implementation.
 */
----

Is created from a `org.hibernate.cfg.AttributeConverterDefinition` or directly from a
	`javax.persistence.AttributeConverter` instance.  Used to determine auto-application


=== Consider adding Return/Fetch graph as part of SQM

or easily buildable from SQM.  The purpose would be determination of of the cacheability of
the query-plan for a given SQM.

This could also facilitate caching query-plans in cases where a load/fetch EntityGraph was specified
assuming the EntityGraph was applied to this SQM "return/fetch graph".  At the moment the presence of a
fetch graph excludes the query-plan from bing cached.

This comes down to a general decision of where the tipping point is for the effectiveness of caching
these plans (size of cache versus resources to build plan).

?Maybe config options stating what to to include in the cache key versus what implicitly means excluding from cache?